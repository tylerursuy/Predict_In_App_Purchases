{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import boto3 \n",
    "from io import StringIO\n",
    "import csv\n",
    "import numpy as np\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Clean Sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions = pd.read_csv(\"../clean_sessions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions_df = sessions.drop(columns=[\"Unnamed: 0\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Sessions (do not need to do again)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions = sessions_file.split(\"\\n\")\n",
    "events = events_file.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_header = sessions[0].split(\",\")\n",
    "event_header = events[0].split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions = sessions[1:]\n",
    "events = events[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions = [row.split(\",\") for row in sessions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_header = session_header[1], session_header[2], session_header[5], session_header[6]\\\n",
    ", session_header[7], session_header[8], session_header[9], session_header[10], session_header[11], \\\n",
    "session_header[12], session_header[19], session_header[21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sessions = []\n",
    "for row in sessions:\n",
    "    if len(row) == 22:\n",
    "        new_sessions.append([row[1], row[2], row[5], row[6], row[7], row[8], row[9], row[10], row[11], \n",
    "                            row[12], row[19], row[21]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions_df = pd.DataFrame(new_sessions, columns=session_header)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions_df = sessions_df.drop(sessions_df[(sessions_df.is_session == \"false\") | \n",
    "                                           (sessions_df.is_developer == \"true\") |\n",
    "                                           (sessions_df.is_wau == \"true\") | \n",
    "                                           (sessions_df.is_mau == \"true\")].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions_df = sessions_df.drop(columns=[\"is_session\", \"is_developer\", \"is_wau\", \"is_mau\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions_df.start_timestamp = sessions_df.start_timestamp.astype(float)\n",
    "sessions_df.previous_sessions_duration = sessions_df.previous_sessions_duration.astype(float)\n",
    "sessions_df.user_created_timestamp = sessions_df.user_created_timestamp.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions_df.start_timestamp = pd.to_datetime(sessions_df.start_timestamp, unit='ms')\n",
    "sessions_df.user_created_timestamp = pd.to_datetime(sessions_df.user_created_timestamp, unit='ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions_df = sessions_df.sort_values(by=[\"start_timestamp\", \"user_id_hash\", \"session_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions_df.to_csv(\"clean_sessions.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = 'ml2-group8' # Add your bucket name\n",
    "events = \"events.csv\"\n",
    "s3 = boto3.resource('s3')\n",
    "bucket = s3.Bucket(bucket_name) \n",
    "events_obj = bucket.Object(key=events) # S3 uses key-value structure where key is your file name\n",
    "events_file = events_obj.get()[\"Body\"].read().decode('utf-8') # Read the Body which is the contents of the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_str = StringIO(events_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_df = pd.read_csv(event_str, sep=\",\", error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_df = events_df.drop(columns=[\"event_value\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_df.event_timestamp = pd.to_datetime(events_df.event_timestamp, unit='ms')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get purchase column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "purchases = [1 if x == \"8\" else 0 for x in events_df.event]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_df[\"purchases\"] = purchases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_df.to_csv(\"../clean_events.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_events = events_df[events_df.event_timestamp >= \"2018-12-01 00:00:00.000\"].sort_values(by=\"event_timestamp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "week1 = dec_events[dec_events.event_timestamp < \"2018-12-08 00:00:00.000\"]\n",
    "week2 = dec_events[dec_events.event_timestamp < \"2018-12-15 00:00:00.000\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "week1_buyers = week1[[\"user_id_hash\", \"purchases\"]].groupby(\"user_id_hash\").sum()\n",
    "week1_buyers[\"week1_purchaser\"] = [1 if x > 0 else 0 for x in week1_buyers.purchases]\n",
    "week1_buyers = week1_buyers.drop(columns=[\"purchases\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "week2_buyers = week2[[\"user_id_hash\", \"purchases\"]].groupby(\"user_id_hash\").sum()\n",
    "week2_buyers[\"week2_purchaser\"] = [1 if x > 0 else 0 for x in week2_buyers.purchases]\n",
    "week2_buyers = week2_buyers.drop(columns=[\"purchases\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_df = week1_buyers.join(week2_buyers, on=\"user_id_hash\", how=\"outer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = sessions_df[sessions_df.start_timestamp < \"2018-12-01 00:00:00.000\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_users = pd.DataFrame(train_df[\"user_id_hash\"].unique(), columns=[\"user_id_hash\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get count of sesssions per user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_counts = train_df[[\"user_id_hash\", \"session_index\"]].groupby(\"user_id_hash\").max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_users = unique_users.join(session_counts, on=\"user_id_hash\", how=\"outer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get total duration of sessions per user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_sum = train_df[[\"user_id_hash\", \"previous_sessions_duration\"]].groupby(\"user_id_hash\").sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get max session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_max = train_df[[\"user_id_hash\", \"session_index\"]].groupby(\"user_id_hash\").max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duration / Session Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "dur_ses = duration_sum.join(session_max, on=\"user_id_hash\", how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "dur_ses[\"duration_session_ratio\"] = dur_ses.previous_sessions_duration / dur_ses.session_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "dur_ses = dur_ses.drop(columns=[\"previous_sessions_duration\", \"session_index\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_users = unique_users.join(dur_ses, on=\"user_id_hash\", how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_users = unique_users.join(dec_df, on=\"user_id_hash\", how=\"left\").fillna(value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_users.to_csv(\"../train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = unique_users.iloc[:495095], unique_users.iloc[495095:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(columns=[\"user_id_hash\", \"week1_purchaser\", \"week2_purchaser\", \"user_enc\", \"hashed\"])\n",
    "X_test = test.drop(columns=[\"user_id_hash\", \"week1_purchaser\", \"week2_purchaser\", \"user_enc\", \"hashed\"])\n",
    "y1_train = train.week1_purchaser\n",
    "y2_train = train.week2_purchaser\n",
    "y1_test = test.week1_purchaser\n",
    "y2_test = test.week2_purchaser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in X_train:\n",
    "    X_train[col] = X_train[col].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "lr_week1 = lr.fit(X_train, y1_train.values)\n",
    "lr_week2 = lr.fit(X_train, y2_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "week1_pred = lr_week1.predict_proba(X_test)[:,0]\n",
    "week1_pred2 = lr_week1.predict_proba(X_train)[:,0]\n",
    "week2_pred = lr_week2.predict_proba(X_test)[:,0]\n",
    "week2_pred2 = lr_week2.predict_proba(X_train)[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8503998173169813"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y1_test, week1_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8438595898785237"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y2_test, week2_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9336167337075638"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y1_train, week1_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9217193156098248"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y2_train, week2_pred2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = 'ml2-group8' # Add your bucket name\n",
    "events = \"sample_submission_2.csv\"\n",
    "s3 = boto3.resource('s3')\n",
    "bucket = s3.Bucket(bucket_name) \n",
    "prediction_obj = bucket.Object(key=events) # S3 uses key-value structure where key is your file name\n",
    "prediction_file = prediction_obj.get()[\"Body\"].read().decode('utf-8') # Read the Body which is the contents of the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = unique_users[[\"session_index\", \"duration_session_ratio\"]]\n",
    "y1 = unique_users.week1_purchaser\n",
    "y2 = unique_users.week2_purchaser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "full_week1 = lr.fit(X, y1)\n",
    "full_week2 = lr.fit(X, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_week1_pred = full_week1.predict_proba(X)[:,0]\n",
    "full_week2_pred = full_week2.predict_proba(X)[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = prediction_file.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_header = predictions[0].split(\",\")\n",
    "predictions = predictions[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['user_id_hash', 'user_purchase_binary_7_days', 'user_purchase_binary_14_days']"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in range(len(predictions)):\n",
    "    predictions[row] = predictions[row].split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame(predictions, columns=prediction_header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.to_csv(\"../sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_users = np.array(pred_df.user_id_hash.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_users = np.array(unique_users.user_id_hash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
